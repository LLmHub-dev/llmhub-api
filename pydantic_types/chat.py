from typing import List, Optional
from pydantic import BaseModel, Field, validator


class Message(BaseModel):
    role: str = Field(
        ...,
        description='The role of the message. Can be "system", "user", or "assistant".',
    )
    content: str = Field(..., description="The content of the message.")


class ImageUrl(BaseModel):
    url: str = Field(..., description="The URL of the image.")


class ImageContent(BaseModel):
    type: str = Field(..., description='The type of content. Must be "image_url".')
    image_url: ImageUrl = Field(..., description="The URL of the image.")


class ToolCall(BaseModel):
    id: str = Field(..., description="A unique identifier for the tool call.")
    type: str = Field(
        ...,
        description='The type of the tool call. Currently, only "function" is supported.',
    )
    function: dict = Field(..., description="The function to call.")


class ChatCompletionChoice(BaseModel):
    index: int = Field(
        ..., description="The index of the choice in the list of choices."
    )
    message: dict = Field(..., description="The message object.")
    logprobs: Optional[dict] = Field(
        None, description="The log probabilities of the tokens in the completion."
    )
    finish_reason: Optional[str] = Field(
        None, description="The reason why the generation stopped."
    )
    delta: Optional[dict] = Field(
        None, description="The changes to the message object. Only used for streaming."
    )


class Usage(BaseModel):
    prompt_tokens: int = Field(..., description="The number of tokens in the prompt.")
    completion_tokens: int = Field(
        ..., description="The number of tokens in the completion."
    )
    total_tokens: int = Field(..., description="The total number of tokens used.")
    completion_tokens_details: Optional[dict] = Field(
        None, description="Details about the completion tokens used."
    )


class ChatCompletion(BaseModel):
    id: str = Field(..., description="The ID of the chat completion.")
    object: str = Field(
        ..., description='The type of the object. Will be "chat.completion".'
    )
    created: int = Field(..., description="The timestamp of the completion.")
    model: str = Field(..., description="The model used to generate the completion.")
    choices: List[ChatCompletionChoice] = Field(
        ..., description="The list of choices generated by the model."
    )
    usage: Usage = Field(..., description="The usage of the model.")
    system_fingerprint: Optional[str] = Field(
        None, description="The system fingerprint for the request."
    )


# metadata,logit_bias
class CreateChatCompletionRequest(BaseModel):
    model: str = Field(..., description="The ID of the model to use.")
    messages: List[Message] = Field(
        ..., description="The messages to send to the model."
    )
    temperature: float = Field(
        0.5,
        description="What sampling temperature to use, between 0 and 2. Higher values like 2 will make the output more random, while lower values like 0 will make it more deterministic.",
    )
    top_p: float = Field(
        1.0,
        description="An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.",
    )
    n: int = Field(
        1,
        description="How many chat completion choices to generate for each input message.",
    )
    stream: bool = Field(False, description="Whether to stream back partial responses.")
    logprobs: bool = Field(
        False,
        description="Whether to include the log probabilities of the tokens in the completion.",
    )
    top_logprobs: int = Field(
        1, description="The maximum number of log probability entries to include."
    )
    max_completion_tokens: int = Field(
        None,
        description="The maximum number of tokens to generate in the completion. The token count of your prompt plus max_completion_tokens cannot exceed the model's context length.",
    )
    presence_penalty: float = Field(
        0.0,
        description="Number between -2.0 and 2.0. Positive values penalize new tokens based on their presence in the text so far.  [See more information about frequency penalties](https://platform.openai.com/docs/guides/text-generation/frequency-penalties).",
    )
    frequency_penalty: float = Field(
        0.0,
        description="Number between -2.0 and 2.0. Positive values penalize new tokens based on their frequency in the text so far. [See more information about frequency penalties](https://platform.openai.com/docs/guides/text-generation/frequency-penalties).",
    )
    stop: Optional[List[str]] = Field(
        None,
        description="Up to 4 sequences where the API will stop generating tokens.  Responds with the generated tokens up to the stopping sequence.  It can be useful to set this to avoid generating tokens after a specific sequence.  [See more information about stopping sequences](https://platform.openai.com/docs/guides/text-generation/stopping-sequences).",
    )
    user: Optional[str] = Field(
        None,
        description="A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.",
    )
    tools: Optional[List[ToolCall]] = Field(
        None,
        description="A list of tools that the model can use to generate a response.",
    )
    tool_choice: Optional[str] = Field(
        None,
        description="How to use the provided tools. If `auto`, the model will choose which tools to use. If `manual`, the model will only use tools specified by the `tool_code` field in the `message` object.",
    )

    @validator("messages")
    def messages_must_contain_at_least_one_user_message(cls, v):
        user_messages = [msg for msg in v if msg.role == "user"]
        if not user_messages:
            raise ValueError("Messages must contain at least one user message")
        return v


class CreateChatCompletionResponse(BaseModel):
    id: str = Field(..., description="The ID of the chat completion.")
    object: str = Field(
        ..., description='The type of the object. Will be "chat.completion".'
    )
    created: int = Field(..., description="The timestamp of the completion.")
    model: str = Field(..., description="The model used to generate the completion.")
    choices: List[ChatCompletionChoice] = Field(
        ..., description="The list of choices generated by the model."
    )
    usage: Usage = Field(..., description="The usage of the model.")
    system_fingerprint: Optional[str] = Field(
        None, description="The system fingerprint for the request."
    )
